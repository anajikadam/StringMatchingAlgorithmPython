{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@m.nath/fuzzy-matching-algorithms-81914b1bc498"
      ],
      "metadata": {
        "id": "O2XUagXDAcer"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1nA96RyAJTV"
      },
      "source": [
        "\n",
        "- [Introduction to fuzzy matching](#inro)\n",
        "- [Applications of fuzzy matching](#applications)\n",
        "- [Algorithms used for fuzzy matching](#algo)\n",
        "    - [Levenshtein distance algorithm](#lev)\n",
        "    - [Damerau-Levenshtein distance algorithm](#dlev)\n",
        "    - [Bitmap algorithm](#bitap)\n",
        "    - [n-gram algorithm](#ngram)\n",
        "- [Implementation of fuzzy matching on real data](#real)\n",
        "- [Other algorithms](#others)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjzVscCBAJTW"
      },
      "source": [
        "<a id = 'intro'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2GgzIlWAJTX"
      },
      "source": [
        "<!-- ![image.png](attachment:cec83173-d5cd-4689-8e25-93ab4e5c28fd.png) -->\n",
        "\n",
        "- Method to find strings which match a pattern approximately.\n",
        "- Identifies the likelihood/probability that two records are true match based on some parameters.\n",
        "\n",
        "<!-- ![image.png](attachment:10f32fe3-2664-4602-8916-41a2a2f7d3bf.png) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tdx4N-PAJTY"
      },
      "source": [
        "<!-- ![image.png](attachment:ed8a9766-a832-4c2f-b3ab-9b80de80c4e4.png) -->\n",
        "\n",
        "- Spell checker\n",
        "- Deduplication of records\n",
        "- Master data management\n",
        "- Plagiarism detection\n",
        "- Bioinformatics and DNA sequencing\n",
        "- Spam filtering\n",
        "- Content search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYGh_mLIAJTZ"
      },
      "source": [
        "<a id = 'algo'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kdHGgQFAJTZ"
      },
      "source": [
        "![image.png](attachment:4e03ed85-7d7f-417c-a226-e2a74a4df25f.png)\n",
        "\n",
        "- Edit distance metric - quantifies how dissimilar two strings are by counting the minimum number of operations required to transform one string into the other\n",
        "    - Levenshtein distance\n",
        "    - Damerauâ€“Levenshtein distance\n",
        "- Bitap algorithm - tells whether a given text contains a substring which is \"approximately equal\" (defined in terms of Levenshtein distance) to a given pattern\n",
        "- n-gram - predicts next item in a sequence of text (in form of a Markov model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdNuM7hgAJTa"
      },
      "source": [
        "![image.png](attachment:d3d721d8-6b72-4904-95ea-03497287204e.png)\n",
        "\n",
        "measures the number of edits needed to transform one word into another\n",
        "\n",
        "![image.png](attachment:886c1ed4-1a6f-4c8e-bd8c-049bdf66edb9.png)\n",
        "\n",
        "![image.png](attachment:6060930b-ba2b-40f1-9ceb-093610d91562.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twxvH9auAJTa"
      },
      "source": [
        "<a id = 'lev'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztZDdLjfAJTb"
      },
      "source": [
        "![image.png](attachment:50d382b8-a530-477e-8b9e-156beb647e30.png)\n",
        "\n",
        "Levenshtein distance has the following properties:\n",
        "\n",
        "- It is zero if and only if the strings are equal.\n",
        "- It is at least the difference of the sizes of the two strings.\n",
        "- It is at most the length of the longer string.\n",
        "- Triangle inequality: The Levenshtein distance between two strings is no greater than the sum of their Levenshtein distances from a third string.\n",
        "\n",
        "\n",
        "The Levenshtein distance between two strings a and b is given by $lev_{a,b}(len(a), len(b))$.\n",
        "\n",
        "The Levenshtein distance between two strings 'a' and 'b', $lev_{a,b}(len(a), len(b))$,\n",
        "where $lev_{a,b}(i, j)$ is equal to\n",
        "\n",
        "$$\n",
        "\\begin{array}\n",
        "& max(i, j) {\\quad} if {\\quad} min(i, j)=0 \\\\\n",
        "{\\text{otherwise:}} \\\\\n",
        "\\\\\n",
        "min \\big(lev_{a,b}(i-1, j) + 1, \\\\\n",
        "{\\qquad} lev_{a,b}(i, j-1) + 1,  \\\\\n",
        "{\\qquad} lev_{a,b}(i-1, j-1) + 1_{a_i \\neq b_j} \\big)\n",
        "\\end{array}    \n",
        "$$    \n",
        "where $1_{a_i \\neq b_j}$ is the indicator function,\n",
        "$$\\begin{array}\n",
        "& 1_{a_i \\neq b_j} & = 0, {\\text{when }} a_i = b_j \\\\\n",
        "& = 1, {\\text{otherwise}}\n",
        "\\end{array}$$\n",
        "\n",
        "and $lev_{a,b}(i, j)$ is the distance between the first i characters of 'a' and the first j characters of 'b'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABij-xlxAJTb"
      },
      "outputs": [],
      "source": [
        "def levdist(s, t):\n",
        "    '''function to calculate the\n",
        "    Levenshtein distance between\n",
        "    two strings in a recursive way'''\n",
        "\n",
        "    if s == '':\n",
        "        return len(t)\n",
        "    if t == '':\n",
        "        return len(s)\n",
        "    if s[-1] == t[-1]:\n",
        "        cost = 0\n",
        "    else:\n",
        "        cost = 1\n",
        "\n",
        "    dist = min([levdist(s[:-1], t)+1,\n",
        "               levdist(s, t[:-1])+1,\n",
        "               levdist(s[:-1], t[:-1]) + cost])\n",
        "\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAvegC0ZAJTd",
        "outputId": "2a97e588-3194-440d-e262-7eabd612d55e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "levdist('irks', 'risk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nULMv6bJAJTe",
        "outputId": "4630ddbc-76d0-49c6-ae51-20e0fbcd69a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Levenshtein distance between  micrsft  and  microsoft corporation  is: 14\n",
            "time taken to calculate Levenshtein distance between  micrsft  and  microsoft corporation  is: 28.52 s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "st = time.time()\n",
        "s1 = 'micrsft'\n",
        "s2 = 'microsoft corporation'\n",
        "print('Levenshtein distance between ',\n",
        "      f'{s1}', ' and ', f'{s2}', ' is:', levdist(s1, s2))\n",
        "et = time.time()\n",
        "print('time taken to calculate Levenshtein distance between ',\n",
        "      f'{s1}', ' and ', f'{s2}', ' is:', round(et-st, 2), 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3tK8yN4AJTf"
      },
      "source": [
        "### This is slow!\n",
        "\n",
        "### Iterative computation using matrix improves the computation time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYioe86dAJTf"
      },
      "outputs": [],
      "source": [
        "def iterative_levdist(s, t):\n",
        "    '''function to calculate the\n",
        "    Levenshtein distance between\n",
        "    two strings in an iterative way'''\n",
        "\n",
        "    rows = len(s)+1\n",
        "    cols = len(t)+1\n",
        "    dist = [[0 for x in range(cols)] for x in range(rows)]\n",
        "\n",
        "    # source prefixes can be transformed into empty strings\n",
        "    # by deletions:\n",
        "    for i in range(1, rows):\n",
        "        dist[i][0] = i\n",
        "\n",
        "    # target prefixes can be created from an empty source string\n",
        "    # by inserting the characters\n",
        "    for i in range(1, cols):\n",
        "        dist[0][i] = i\n",
        "\n",
        "    for col in range(1, cols):\n",
        "        for row in range(1, rows):\n",
        "            if s[row-1] == t[col-1]:\n",
        "                cost = 0\n",
        "            else:\n",
        "                cost = 1\n",
        "            dist[row][col] = min(dist[row-1][col] + 1,      # deletion\n",
        "                                 dist[row][col-1] + 1,      # insertion\n",
        "                                 dist[row-1][col-1] + cost) # substitution\n",
        "\n",
        "\n",
        "    return dist[row][col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwuAufwbAJTg",
        "outputId": "1f1b7cce-68c3-43c9-c946-afb9af5f7798"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iterative_levdist('irks', 'risk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBAUCagzAJTg",
        "outputId": "341ccf11-b57b-4fe9-f5f4-6f0fb1ea4fe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Levenshtein distance between  micrsft  and  microsoft corporation  is: 14\n",
            "time taken to calculate Levenshtein distance between  micrsft  and  microsoft corporation  is: 0.0 s\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "s1 = 'micrsft'\n",
        "s2 = 'microsoft corporation'\n",
        "print('Levenshtein distance between ',\n",
        "      f'{s1}', ' and ', f'{s2}', ' is:', iterative_levdist(s1, s2))\n",
        "et = time.time()\n",
        "print('time taken to calculate Levenshtein distance between ',\n",
        "      f'{s1}', ' and ', f'{s2}', ' is:', round(et-st, 2), 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-2DvC_vAJTh"
      },
      "source": [
        "<a id = 'dlev'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRv-4iBzAJTh"
      },
      "source": [
        "### Damerau-Levenshtein Distance works similar to Levenshtein distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVv4z07YAJTh"
      },
      "source": [
        "#### To install jellyfish package, pip install jellyfish\n",
        "Refer [here](https://pypi.org/project/jellyfish/) for more information on this package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aY3GPbyAJTi",
        "outputId": "bc569b78-2e66-4cb5-b251-ac2a88d72447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Levenshtein distance is:  3\n",
            "Damerau-Levenshtein distance is:  2\n"
          ]
        }
      ],
      "source": [
        "import jellyfish\n",
        "\n",
        "print('Levenshtein distance is: ', jellyfish.levenshtein_distance('irks', 'risk'))\n",
        "print('Damerau-Levenshtein distance is: ', jellyfish.damerau_levenshtein_distance('irks', 'risk'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhxvpSQRAJTj",
        "outputId": "3f4c4946-f875-4d67-b359-9ee3fe1df8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Damerau-Levenshtein distance between  micrsft  and  microsoft corporation  is: 14\n",
            "time taken to calculate Damerau-Levenshtein distance between  micrsft  and  microsoft corporation  is: 0.0 s\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "s1 = 'micrsft'\n",
        "s2 = 'microsoft corporation'\n",
        "print('Damerau-Levenshtein distance between ',\n",
        "      f'{s1}', ' and ', f'{s2}', ' is:', jellyfish.damerau_levenshtein_distance(s1, s2))\n",
        "et = time.time()\n",
        "print('time taken to calculate Damerau-Levenshtein distance between ',\n",
        "      f'{s1}', ' and ', f'{s2}', ' is:', round(et-st, 2), 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT5ZoTzQAJTj"
      },
      "source": [
        "<a id = 'bitap'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqyBRiv-AJTk"
      },
      "source": [
        "![image.png](attachment:d0c7cfbc-f0e6-4a67-9df0-f9a889917d64.png)\n",
        "\n",
        "- also known as the shift-or, shift-and or Baeza-Yatesâ€“Gonnet algorithm\n",
        "- states whether a given text contains a substring which is \"approximately equal\" (defined by Levenshtein distance) to a given pattern.\n",
        "\n",
        "\n",
        "**Input:**\n",
        "\n",
        "Text: womenwhocode\n",
        "\n",
        "Pattern: code\n",
        "\n",
        "**Output:**\n",
        "Pattern found at index: 8\n",
        "\n",
        "**Input:**\n",
        "\n",
        "Text: youareawesome\n",
        "\n",
        "Pattern: youareamazing\n",
        "\n",
        "**Output:** No Match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xikvQEoiAJTk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def bitap_search(text, pattern):\n",
        "\n",
        "    '''function to do a bit-ap search\n",
        "    using bit array\n",
        "    (this is python implementation of the\n",
        "    code in GeekforGeeks)'''\n",
        "\n",
        "    len_pattern = len(pattern)\n",
        "\n",
        "    #initializing the bit array to complement of 0\n",
        "    bit_array = [~0] * (sys.maxunicode)\n",
        "\n",
        "    # R is a variable, initiliazing it to complement of 1\n",
        "    R = ~1\n",
        "\n",
        "    # taking care of the edge cases\n",
        "    # when the pattern is absent\n",
        "    # or when the pattern is longer than the text\n",
        "    if len_pattern == 0:\n",
        "        return -1\n",
        "\n",
        "    if len_pattern > len(text):\n",
        "        print('Pattern too long!')\n",
        "        return -1\n",
        "\n",
        "\n",
        "    for i in range(len_pattern):\n",
        "        bit_array[ord(pattern[i])] &= ~(1 << i)\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        R |= bit_array[ord(text[i])]\n",
        "        R <<= 1;\n",
        "        if (R & (1 << len_pattern)) == 0:\n",
        "            return i - len_pattern + 1\n",
        "\n",
        "    return -1\n",
        "\n",
        "\n",
        "\n",
        "def findPattern(t, p):\n",
        "    text = list(t);\n",
        "    pattern = list(p);\n",
        "    index = bitap_search(text, pattern);\n",
        "    if index == -1:\n",
        "        print('No Match')\n",
        "    else:\n",
        "        print('Pattern found at index:', index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bze2DsBFAJTk",
        "outputId": "33982247-076a-4e7e-a135-0eae93f0561c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pattern found at index: 8\n"
          ]
        }
      ],
      "source": [
        "text = 'womenwhocode'\n",
        "pattern = 'code'\n",
        "\n",
        "findPattern(text, pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga2ZH0-2AJTl",
        "outputId": "5b61855b-ef42-479a-92d8-eb5844d2b8b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No Match\n"
          ]
        }
      ],
      "source": [
        "text = 'youareamazing'\n",
        "pattern = 'youareawesome'\n",
        "\n",
        "findPattern(text, pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PzZny3aAJTl"
      },
      "source": [
        "<a id = 'ngram'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGq9QpOpAJTm"
      },
      "source": [
        "![image.png](attachment:444fed96-f05c-49e8-80b3-06c74af83568.png)\n",
        "\n",
        "- n-gram: set of values generated from a string by pairing sequentially occurring â€˜nâ€™ characters/words\n",
        "- goal: compute probability of a sequence of characters/words or sentence\n",
        "- predicts next item in a sequence of text (in form of a Markov model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By1xmzH_AJTm"
      },
      "source": [
        "### PROBABILITY\n",
        "\n",
        "Conditional probability with 2 variables/words:\n",
        "\n",
        "$$ \\large{p(w_1 \\cap w_2) = p(w_1) p(w_2|w_1)}$$\n",
        "\n",
        "Conditional probability with 4 variables/words:\n",
        "\n",
        "$$\\large{p(w_1 \\cap w_2 \\cap w_3 \\cap w_4) = p(w_1) p(w_2|w_1) p(w_3|w_1 \\cap w_2) p(w_4|w_1 \\cap w_2 \\cap w_3) }$$\n",
        "\n",
        "Therefore, joint probability can be calculated using chain rule:\n",
        "\n",
        "$$\\Large{ p(w_1 \\cap w_2 , \\cdots, w_n) = \\prod_{i} p (w_i|w_1 w_2 \\cdots w_{n-1}) }$$\n",
        "\n",
        "### &nbsp;&nbsp;&nbsp; TOO MANY POSSIBLE COMBINATIONS!!\n",
        "\n",
        "\n",
        "![image.png](attachment:921d674b-470e-4c5e-8359-1db40839d2cb.png)\n",
        "\n",
        "### Approximate each component of the product by maximum likelihood estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNmIV7vyAJTm"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = ['company name is microsoft', 'company the name is Microsoft',\n",
        "          'company name mcrosft', 'the company is Microsft Co',\n",
        "         'company is Microsoft Corporation', 'the company is name microsoft Corp',\n",
        "          'company MCSFT CO name']\n",
        "\n",
        "clean_corpus = ['The company name is Microsoft Corporation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dSqDNK2AJTn",
        "outputId": "bbcd5ab2-dd34-4dc1-edbe-feafebe15a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['co', 'company', 'corp', 'corporation', 'is', 'mcrosft', 'mcsft', 'microsft', 'microsoft', 'name', 'the']\n"
          ]
        }
      ],
      "source": [
        "vect1 = TfidfVectorizer(analyzer='word', ngram_range=(1, 1))\n",
        "x = vect1.fit_transform(corpus)\n",
        "\n",
        "print(vect1.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6Gjmvo-AJTn",
        "outputId": "5f83cdd9-7aeb-4761-ca97-4882e33dc5aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['company is microsft', 'company is microsoft', 'company is name', 'company mcsft co', 'company name is', 'company name mcrosft', 'company the name', 'is microsft co', 'is microsoft corporation', 'is name microsoft', 'mcsft co name', 'name is microsoft', 'name microsoft corp', 'the company is', 'the name is']\n"
          ]
        }
      ],
      "source": [
        "vect2 = TfidfVectorizer(analyzer='word', ngram_range=(3, 3))\n",
        "x = vect2.fit_transform(corpus)\n",
        "\n",
        "print(vect2.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5EgIo6aAJTn",
        "outputId": "2b0d2228-99be-47bc-8999-9f06af2d1cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['co name', 'company is', 'company is microsft', 'company is microsft co', 'company is microsoft', 'company is microsoft corporation', 'company is name', 'company is name microsoft', 'company is name microsoft corp', 'company mcsft', 'company mcsft co', 'company mcsft co name', 'company name', 'company name is', 'company name is microsoft', 'company name mcrosft', 'company the', 'company the name', 'company the name is', 'company the name is microsoft', 'is microsft', 'is microsft co', 'is microsoft', 'is microsoft corporation', 'is name', 'is name microsoft', 'is name microsoft corp', 'mcsft co', 'mcsft co name', 'microsft co', 'microsoft corp', 'microsoft corporation', 'name is', 'name is microsoft', 'name mcrosft', 'name microsoft', 'name microsoft corp', 'the company', 'the company is', 'the company is microsft', 'the company is microsft co', 'the company is name', 'the company is name microsoft', 'the name', 'the name is', 'the name is microsoft']\n"
          ]
        }
      ],
      "source": [
        "vect3 = TfidfVectorizer(analyzer='word', ngram_range=(2, 5))\n",
        "x = vect3.fit_transform(corpus)\n",
        "\n",
        "print(vect3.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD4RQZCiAJTo"
      },
      "source": [
        "### Let's implement on this example and compare with Levenshtein distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtRsId1jAJTo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "# for fuzzy matching\n",
        "from fuzzy_match import algorithims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7OeG-x6AJTo",
        "outputId": "96f71933-ede7-40cb-ac07-1d4b2e91cbc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('company name is microsoft', 'The company name is Microsoft Corporation'),\n",
              " ('company the name is Microsoft',\n",
              "  'The company name is Microsoft Corporation'),\n",
              " ('company name mcrosft', 'The company name is Microsoft Corporation'),\n",
              " ('the company is Microsft Co', 'The company name is Microsoft Corporation'),\n",
              " ('company is Microsoft Corporation',\n",
              "  'The company name is Microsoft Corporation'),\n",
              " ('the company is name microsoft Corp',\n",
              "  'The company name is Microsoft Corporation'),\n",
              " ('company MCSFT CO name', 'The company name is Microsoft Corporation')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# make a cartesian combination of the words in the corpus and the correct word\n",
        "\n",
        "cart_list = list(itertools.product(corpus, clean_corpus))\n",
        "cart_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPjQxgUMAJTo"
      },
      "outputs": [],
      "source": [
        "def get_matches(lst):\n",
        "\n",
        "    '''function to calculate the Levenshtein\n",
        "    distance, trigram match score and the cosine\n",
        "    similarity matches for the above example'''\n",
        "\n",
        "    x, y, lscore, tscore, cscore = [], [], [], [], []\n",
        "\n",
        "    for i in range(len(lst)):\n",
        "        x.append(lst[i][0])\n",
        "        y.append(lst[i][1])\n",
        "\n",
        "        lscore.append(round(algorithims.levenshtein(lst[i][0], lst[i][1]), 3))\n",
        "        tscore.append(round(algorithims.trigram(lst[i][0], lst[i][1]), 3))\n",
        "        cscore.append(round(algorithims.cosine(lst[i][0], lst[i][1]), 3))\n",
        "\n",
        "    df = pd.DataFrame(list(zip(x, y, lscore, tscore, cscore)),\n",
        "                    columns = ['in_data', 'clean_data', 'lev_score', 'tri_score', 'cosine_score'])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25BWlQZcAJTu",
        "outputId": "8789d420-49f8-436f-d369-091d2af69c7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>in_data</th>\n",
              "      <th>clean_data</th>\n",
              "      <th>lev_score</th>\n",
              "      <th>tri_score</th>\n",
              "      <th>cosine_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>company name is microsoft</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>company the name is Microsoft</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>company name mcrosft</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.463</td>\n",
              "      <td>0.386</td>\n",
              "      <td>0.471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the company is Microsft Co</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>company is Microsoft Corporation</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.775</td>\n",
              "      <td>0.816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the company is name microsoft Corp</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.634</td>\n",
              "      <td>0.780</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>company MCSFT CO name</td>\n",
              "      <td>The company name is Microsoft Corporation</td>\n",
              "      <td>0.293</td>\n",
              "      <td>0.333</td>\n",
              "      <td>0.408</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              in_data  \\\n",
              "0           company name is microsoft   \n",
              "1       company the name is Microsoft   \n",
              "2                company name mcrosft   \n",
              "3          the company is Microsft Co   \n",
              "4    company is Microsoft Corporation   \n",
              "5  the company is name microsoft Corp   \n",
              "6               company MCSFT CO name   \n",
              "\n",
              "                                  clean_data  lev_score  tri_score  \\\n",
              "0  The company name is Microsoft Corporation      0.585      0.650   \n",
              "1  The company name is Microsoft Corporation      0.512      0.750   \n",
              "2  The company name is Microsoft Corporation      0.463      0.386   \n",
              "3  The company name is Microsoft Corporation      0.610      0.512   \n",
              "4  The company name is Microsoft Corporation      0.780      0.775   \n",
              "5  The company name is Microsoft Corporation      0.634      0.780   \n",
              "6  The company name is Microsoft Corporation      0.293      0.333   \n",
              "\n",
              "   cosine_score  \n",
              "0         0.612  \n",
              "1         0.730  \n",
              "2         0.471  \n",
              "3         0.365  \n",
              "4         0.816  \n",
              "5         0.500  \n",
              "6         0.408  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_matches(cart_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HfwA2UYAJTu"
      },
      "source": [
        "<a id = 'real'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX3Tvy1iAJTu"
      },
      "source": [
        "![image.png](attachment:41f29434-62b8-4aa7-a289-50803e332989.png)\n",
        "\n",
        "### Download data [here from Kaggle](https://www.kaggle.com/leandrodoze/room-type).\n",
        "\n",
        "The data contains two columns for room type descriptions. Column 1 is the description from Expedia, and column 2 is the associated room type in Booking.com.\n",
        "\n",
        "<u> **Aim:**</u> is to compare and match these two columns and the result would be 'human like understanding that the matched entries are same'.\n",
        "\n",
        "Packages used:\n",
        "- fuzzywuzzy (Refer [here](https://pypi.org/project/fuzzywuzzy/) for more information).\n",
        "- fuzzy_match (Refer [here](https://pypi.org/project/fuzzy-match/) for more information)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZjgTjdwAJTv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "\n",
        "# this is for fuzzy matching\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzy_match import algorithims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NVMozfJAJTv"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('room_type.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HWyVp9wAJTv",
        "outputId": "b1b22292-36e0-4327-aad0-8bb15d2d5ca0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Expedia</th>\n",
              "      <th>Booking.com</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Deluxe Room, 1 King Bed</td>\n",
              "      <td>Deluxe King Room</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Standard Room, 1 King Bed, Accessible</td>\n",
              "      <td>Standard King Roll-in Shower Accessible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grand Corner King Room, 1 King Bed</td>\n",
              "      <td>Grand Corner King Room</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suite, 1 King Bed (Parlor)</td>\n",
              "      <td>King Parlor Suite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>High-Floor Premium Room, 1 King Bed</td>\n",
              "      <td>High-Floor Premium King Room</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Expedia  \\\n",
              "0                Deluxe Room, 1 King Bed   \n",
              "1  Standard Room, 1 King Bed, Accessible   \n",
              "2     Grand Corner King Room, 1 King Bed   \n",
              "3             Suite, 1 King Bed (Parlor)   \n",
              "4    High-Floor Premium Room, 1 King Bed   \n",
              "\n",
              "                               Booking.com  \n",
              "0                         Deluxe King Room  \n",
              "1  Standard King Roll-in Shower Accessible  \n",
              "2                   Grand Corner King Room  \n",
              "3                        King Parlor Suite  \n",
              "4             High-Floor Premium King Room  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV41inC5AJTw"
      },
      "source": [
        "#### RATIO - Compares the entire string similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a18ZCmIGAJTw"
      },
      "outputs": [],
      "source": [
        "def get_ratio(row):\n",
        "\n",
        "    '''function to compare the values in each row\n",
        "    for the two columns in the same dataframe and\n",
        "    return the ratio for the entire string similarity'''\n",
        "\n",
        "    col1 = row['Expedia']\n",
        "    col2 = row['Booking.com']\n",
        "\n",
        "    return fuzz.ratio(col1, col2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BC0b4AWAJTw"
      },
      "source": [
        "#### PARTIAL RATIO - Compares partial string similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA6HkkGuAJTw"
      },
      "outputs": [],
      "source": [
        "def get_partial_ratio(row):\n",
        "\n",
        "    '''function to compare the values in each row\n",
        "    for the two columns in the same dataframeand\n",
        "    return the ratio for partial string similarity'''\n",
        "\n",
        "    col1 = row['Expedia']\n",
        "    col2 = row['Booking.com']\n",
        "\n",
        "    return fuzz.partial_ratio(col1, col2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28t8hJcsAJTx"
      },
      "source": [
        "#### TOKEN SORT RATIO - Ignores word order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4GHmUkdAJTx"
      },
      "outputs": [],
      "source": [
        "def get_token_sort_ratio(row):\n",
        "\n",
        "    '''function to compare the values in each row\n",
        "    for the two columns in the same dataframeand\n",
        "    return the ratio for string similarity by\n",
        "    ignoring word order'''\n",
        "\n",
        "    col1 = row['Expedia']\n",
        "    col2 = row['Booking.com']\n",
        "\n",
        "    return fuzz.token_sort_ratio(col1, col2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPsSsJIwAJTx"
      },
      "source": [
        "#### TOKEN SET RATIO - Ignore duplicate words similarly to token sort ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdagf3-TAJTx"
      },
      "outputs": [],
      "source": [
        "def get_token_set_ratio(row):\n",
        "\n",
        "    '''function to compare the values in each row\n",
        "    for the two columns in the same dataframeand\n",
        "    return the ratio for string similarity by\n",
        "    ignoring duplicate words and word order'''\n",
        "\n",
        "    col1 = row['Expedia']\n",
        "    col2 = row['Booking.com']\n",
        "\n",
        "    return fuzz.token_set_ratio(col1, col2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbDG3zUjAJTy"
      },
      "source": [
        "#### TRIGRAM - Calculates a similarity score and find matches by splitting strings into ngrams with a length of 3. The length of the ngram can be altered if desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taj6LYjPAJTy"
      },
      "outputs": [],
      "source": [
        "def get_trigram_value(row):\n",
        "\n",
        "    '''function to compare the values in each row\n",
        "    for the two columns in the same dataframeand\n",
        "    return the ratio for string similarity by\n",
        "    ignoring duplicate words and word order'''\n",
        "\n",
        "    col1 = row['Expedia']\n",
        "    col2 = row['Booking.com']\n",
        "\n",
        "    return round(algorithims.trigram(col1, col2), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8qqEvrXAJTy",
        "outputId": "a0c6dfa2-a461-4022-d3e1-226dba89ccf5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Expedia</th>\n",
              "      <th>Booking.com</th>\n",
              "      <th>full_ratio</th>\n",
              "      <th>partial_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>trigram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Deluxe Room, 1 King Bed</td>\n",
              "      <td>Deluxe King Room</td>\n",
              "      <td>62</td>\n",
              "      <td>69</td>\n",
              "      <td>84</td>\n",
              "      <td>100</td>\n",
              "      <td>0.739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Standard Room, 1 King Bed, Accessible</td>\n",
              "      <td>Standard King Roll-in Shower Accessible</td>\n",
              "      <td>68</td>\n",
              "      <td>65</td>\n",
              "      <td>78</td>\n",
              "      <td>81</td>\n",
              "      <td>0.562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Grand Corner King Room, 1 King Bed</td>\n",
              "      <td>Grand Corner King Room</td>\n",
              "      <td>79</td>\n",
              "      <td>100</td>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>0.793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Suite, 1 King Bed (Parlor)</td>\n",
              "      <td>King Parlor Suite</td>\n",
              "      <td>51</td>\n",
              "      <td>65</td>\n",
              "      <td>85</td>\n",
              "      <td>100</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>High-Floor Premium Room, 1 King Bed</td>\n",
              "      <td>High-Floor Premium King Room</td>\n",
              "      <td>76</td>\n",
              "      <td>82</td>\n",
              "      <td>90</td>\n",
              "      <td>100</td>\n",
              "      <td>0.829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Expedia  \\\n",
              "0                Deluxe Room, 1 King Bed   \n",
              "1  Standard Room, 1 King Bed, Accessible   \n",
              "2     Grand Corner King Room, 1 King Bed   \n",
              "3             Suite, 1 King Bed (Parlor)   \n",
              "4    High-Floor Premium Room, 1 King Bed   \n",
              "\n",
              "                               Booking.com  full_ratio  partial_ratio  \\\n",
              "0                         Deluxe King Room          62             69   \n",
              "1  Standard King Roll-in Shower Accessible          68             65   \n",
              "2                   Grand Corner King Room          79            100   \n",
              "3                        King Parlor Suite          51             65   \n",
              "4             High-Floor Premium King Room          76             82   \n",
              "\n",
              "   token_sort_ratio  token_set_ratio  trigram  \n",
              "0                84              100    0.739  \n",
              "1                78               81    0.562  \n",
              "2                80              100    0.793  \n",
              "3                85              100    0.750  \n",
              "4                90              100    0.829  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df['full_ratio'] = data_df.apply(get_ratio, axis=1)\n",
        "data_df['partial_ratio'] = data_df.apply(get_partial_ratio, axis=1)\n",
        "data_df['token_sort_ratio'] = data_df.apply(get_token_sort_ratio, axis=1)\n",
        "data_df['token_set_ratio'] = data_df.apply(get_token_set_ratio, axis=1)\n",
        "data_df['trigram'] = data_df.apply(get_trigram_value, axis=1)\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxcYF-QLAJTz"
      },
      "source": [
        "####  It looks like TOKEN SET RATIO from fuzzywuzzy package is the best method to get the most similar matches in this example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfY132FRAJTz"
      },
      "source": [
        "<a id = 'others'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2lY97f1AJTz"
      },
      "source": [
        "![image.png](attachment:fda7874a-b7b2-484e-b187-397b35c93cd6.png)\n",
        "\n",
        "- Edit distance\n",
        "    - Longest common subsequence\n",
        "    - Hamming distance\n",
        "    - Jaro distance\n",
        "- Needlemanâ€“Wunsch algorithm\n",
        "- Smithâ€“Waterman algorithm\n",
        "- BK Tree metric\n",
        "- Soundex or Metaphone â€“ phonetic algorithms\n",
        "\n",
        "[Record Linkange Toolkit](https://recordlinkage.readthedocs.io/en/latest/about.html) library to link records in or between data sources and provides tools for deduplication and record linkage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYVrgxkAAJT0"
      },
      "source": [
        "# REFERENCES\n",
        "1. [Levenshtein, Vladimir I. \"Binary codes capable of correcting deletions, insertions, and reversals.\" In Soviet physics doklady, vol. 10, no. 8, pp. 707-710. 1966.](https://nymity.ch/sybilhunting/pdf/Levenshtein1966a.pdf)\n",
        "2. [Damerau, Fred J. \"A technique for computer detection and correction of spelling errors.\" Communications of the ACM 7, no. 3 (1964): 171-176.](https://dl.acm.org/doi/abs/10.1145/363958.363994)\n",
        "3. [Cayrol, M., Farreny, H. and Prade, H. (1982), 'Fuzzy Pattern Matching', Kybernetes, Vol. 11 No. 2, pp. 103-116.](https://doi.org/10.1108/eb005612)\n",
        "4. [Ukkonen, Esko. \"Algorithms for approximate string matching.\" Information and control 64, no. 1-3 (1985): 100-118.](https://reader.elsevier.com/reader/sd/pii/S0019995885800462?token=6B1FB04FFCA70F0F9A2AAB96C6311FAA5E93FFB7F1C1B4A75A61D72728A2B6A655B4944421AD983395F0B11AAB73F520&originRegion=us-east-1&originCreation=20210331153641)\n",
        "5. [Geek for Geeks - applications of fuzzy string matching](https://www.geeksforgeeks.org/applications-of-string-matching-algorithms/)\n",
        "6. [Geek for Geeks - Bitap Algorithm](https://www.geeksforgeeks.org/java-program-to-implement-bitap-algorithm-for-string-matching/)\n",
        "7. [Stanford slides on n-gram](https://web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf)\n",
        "8. [Data camp tutorial - fuzzy string matching](https://www.datacamp.com/community/tutorials/fuzzy-string-python)\n",
        "9. [Levenshtein distance theory](https://www.python-course.eu/levenshtein_distance.php)\n",
        "10. [Article on record linking and fuzzy matching](https://pbpython.com/record-linking.html)\n",
        "11. [Medium post on Levenshtein distance](https://blog.paperspace.com/measuring-text-similarity-using-levenshtein-distance/)\n",
        "12. [stackoverflow for n-gram similarity](https://stackoverflow.com/questions/53827339/string-matching-using-tf-idf-ngrams-and-cosine-similarity-in-python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkPYIRaDAJT0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}